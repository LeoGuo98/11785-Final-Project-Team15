{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diginetica_preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1FI3Gdlb1Ev"
      },
      "source": [
        "import time\n",
        "import csv\n",
        "import pickle\n",
        "\n",
        "import operator\n",
        "item_to_cat = {}\n",
        "\n",
        "with open(\"./product-categories.csv\") as f:\n",
        "    reader = csv.DictReader(f, delimiter=';')\n",
        "    for data in reader:\n",
        "        item_to_cat[data['itemId']] = data['categoryId']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etEZU__LwsjM",
        "outputId": "37da6453-f8b6-4f58-966b-7c65749c47a6"
      },
      "source": [
        "import time\n",
        "import csv\n",
        "import pickle\n",
        "\n",
        "import operator\n",
        "\n",
        "# Load the diginetica dataset\n",
        "with open(\"./train-item-views.csv\") as f:\n",
        "    reader = csv.DictReader(f, delimiter=';')\n",
        "    sess_clicks = {}\n",
        "    # Only keep the 'starting' date for each session\n",
        "    sess_date = {}\n",
        "    ctr = 0\n",
        "    curid = -1\n",
        "    curdate = None\n",
        "    for data in reader:\n",
        "        sessid = data['sessionId']\n",
        "        if curdate and not curid == sessid:\n",
        "            date = time.mktime(time.strptime(curdate, '%Y-%m-%d'))\n",
        "            sess_date[curid] = date\n",
        "        curid = sessid\n",
        "        item = data['itemId']\n",
        "        curdate = data['eventdate']\n",
        "        timeframe = int(data['timeframe'])\n",
        "        if sessid in sess_clicks:\n",
        "            sess_clicks[sessid] += [(timeframe, item)]\n",
        "        else:\n",
        "            sess_clicks[sessid] = [(timeframe, item)]\n",
        "        ctr += 1\n",
        "        if ctr % 100000 == 0:\n",
        "            print ('Loaded', ctr)\n",
        "    date = time.mktime(time.strptime(curdate, '%Y-%m-%d'))\n",
        "    sess_date[curid] = date\n",
        "\n",
        "for s in sess_clicks.keys():\n",
        "    l = sorted(sess_clicks[s])\n",
        "    sess_clicks[s] = [x[1] for x in l]\n",
        "\n",
        "# Filter out length 1 sessions\n",
        "to_be_deleted = []\n",
        "for s in sess_clicks.keys():\n",
        "    if len(sess_clicks[s]) == 1:\n",
        "        to_be_deleted.append(s)\n",
        "for s in to_be_deleted:\n",
        "    del sess_clicks[s]\n",
        "    del sess_date[s]\n",
        "\n",
        "# Count number of times each item appears\n",
        "iid_counts = {}\n",
        "for s in sess_clicks:\n",
        "    seq = sess_clicks[s]\n",
        "    for iid in seq:\n",
        "        if iid in iid_counts:\n",
        "            iid_counts[iid] += 1\n",
        "        else:\n",
        "            iid_counts[iid] = 1\n",
        "\n",
        "sorted_counts = sorted(iid_counts.items(), key=operator.itemgetter(1))\n",
        "\n",
        "to_be_deleted = []\n",
        "for s in sess_clicks.keys():\n",
        "    curseq = sess_clicks[s]\n",
        "    filseq = list(filter(lambda i: iid_counts[i] >= 5, curseq))\n",
        "    if len(filseq) < 2:\n",
        "        to_be_deleted.append(s)\n",
        "    else:\n",
        "        sess_clicks[s] = filseq\n",
        "\n",
        "for s in to_be_deleted:\n",
        "    del sess_clicks[s]\n",
        "    del sess_date[s]\n",
        "\n",
        "# Split out test set based on dates\n",
        "dates = list(sess_date.items())\n",
        "maxdate = dates[0][1]\n",
        "\n",
        "for _, date in dates:\n",
        "    if maxdate < date:\n",
        "        maxdate = date\n",
        "\n",
        "# 7 days for test\n",
        "splitdate = maxdate - 86400 * 7\n",
        "print('Split date', splitdate)\n",
        "train_sess = filter(lambda x: x[1] < splitdate, dates)\n",
        "test_sess = filter(lambda x: x[1] > splitdate, dates)\n",
        "\n",
        "# Sort sessions by date\n",
        "train_sess = sorted(train_sess, key=operator.itemgetter(1))\n",
        "test_sess = sorted(test_sess, key=operator.itemgetter(1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 100000\n",
            "Loaded 200000\n",
            "Loaded 300000\n",
            "Loaded 400000\n",
            "Loaded 500000\n",
            "Loaded 600000\n",
            "Loaded 700000\n",
            "Loaded 800000\n",
            "Loaded 900000\n",
            "Loaded 1000000\n",
            "Loaded 1100000\n",
            "Loaded 1200000\n",
            "Split date 1464134400.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QRv3M4Fc4Gh",
        "outputId": "fe958f9c-87ea-41de-f33a-a0728597545a"
      },
      "source": [
        "# Choosing item count >=5 gives approximately the same number of items as reported in paper\n",
        "item_dict = {}\n",
        "item_ctr = 1\n",
        "category_dict = {}\n",
        "category_ctr = 1\n",
        "train_seqs = []\n",
        "train_cat = []\n",
        "train_dates = []\n",
        "\n",
        "id_to_cat_model = {}\n",
        "# Convert training sessions to sequences and renumber items to start from 1\n",
        "for s, date in train_sess:\n",
        "    seq = sess_clicks[s]\n",
        "    outseq = []\n",
        "    cat = []\n",
        "    for i in seq:\n",
        "        if i in item_dict:\n",
        "            outseq += [item_dict[i]]\n",
        "            cat += [category_dict[item_to_cat[i]]]\n",
        "        else:\n",
        "            outseq += [item_ctr]\n",
        "            item_dict[i] = item_ctr\n",
        "            item_ctr += 1\n",
        "            if item_to_cat[i] in category_dict:\n",
        "                id_to_cat_model[item_dict[i]] = category_dict[item_to_cat[i]]\n",
        "                cat += [category_dict[item_to_cat[i]]]\n",
        "            else:\n",
        "                cat += [category_ctr]\n",
        "                category_dict[item_to_cat[i]] = category_ctr\n",
        "                category_ctr += 1\n",
        "                id_to_cat_model[item_dict[i]] = category_dict[item_to_cat[i]]\n",
        "    if len(outseq) < 2:  # Doesn't occur\n",
        "        continue\n",
        "    train_seqs += [outseq]\n",
        "    train_dates += [date]\n",
        "    train_cat += [cat]\n",
        "\n",
        "test_seqs = []\n",
        "test_dates = []\n",
        "test_cat = []\n",
        "# Convert test sessions to sequences, ignoring items that do not appear in training set\n",
        "for s, date in test_sess:\n",
        "    seq = sess_clicks[s]\n",
        "    outseq = []\n",
        "    cat = []\n",
        "    for i in seq:\n",
        "        if i in item_dict:\n",
        "            outseq += [item_dict[i]]\n",
        "            cat += [category_dict[item_to_cat[i]]]\n",
        "    if len(outseq) < 2:\n",
        "        continue\n",
        "    test_seqs += [outseq]\n",
        "    test_dates += [date]\n",
        "    test_cat += [cat]\n",
        "\n",
        "print(item_ctr)\n",
        "print(category_ctr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43098\n",
            "996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjUTe03nfEYP",
        "outputId": "0a617f1e-99d7-4132-8571-dd27a4536640"
      },
      "source": [
        "def process_seqs(iseqs, idates):\n",
        "    out_seqs = []\n",
        "    out_dates = []\n",
        "    labs = []\n",
        "    for seq, date in zip(iseqs, idates):\n",
        "        for i in range(1, len(seq)):\n",
        "            tar = seq[-i]\n",
        "            labs += [tar]\n",
        "            out_seqs += [seq[:-i]]\n",
        "            out_dates += [date]\n",
        "\n",
        "    return out_seqs, out_dates, labs\n",
        "\n",
        "\n",
        "tr_seqs_side, tr_dates_side, tr_labs_side = process_seqs(train_cat,train_dates)\n",
        "te_seqs_side, te_dates_side, te_labs_side = process_seqs(test_cat,test_dates)\n",
        "\n",
        "train_side = (tr_seqs_side, tr_labs_side)\n",
        "test_side = (te_seqs_side, te_labs_side)\n",
        "\n",
        "f1 = open('./digi_train_side.pkl', 'wb')\n",
        "pickle.dump(train_side, f1)\n",
        "f1.close()\n",
        "f2 = open('./digi_test_side.pkl', 'wb')\n",
        "pickle.dump(test_side, f2)\n",
        "f2.close()\n",
        "\n",
        "print('Done.') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fROft__4fmvI",
        "outputId": "d8088e5c-5cfe-463d-c354-1f858223bf86"
      },
      "source": [
        "tr_seqs, tr_dates, tr_labs = process_seqs(train_seqs,train_dates)\n",
        "te_seqs, te_dates, te_labs = process_seqs(test_seqs,test_dates)\n",
        "\n",
        "train = (tr_seqs, tr_labs)\n",
        "test = (te_seqs, te_labs)\n",
        "\n",
        "f1 = open('./digi_train.pkl', 'wb')\n",
        "pickle.dump(train, f1)\n",
        "f1.close()\n",
        "f2 = open('./digi_test.pkl', 'wb')\n",
        "pickle.dump(test, f2)\n",
        "f2.close()\n",
        "\n",
        "print('Done.') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUcORbLm3Rnk"
      },
      "source": [
        "l = []\n",
        "for i in range(1, 43098):\n",
        "    l.append(id_to_cat_model[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzf7FsMg32hZ"
      },
      "source": [
        "import numpy as np\n",
        "index_list = np.array(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tFBIDNaPr1K"
      },
      "source": [
        "f2 = open('./digi_side.pkl', 'wb')\n",
        "pickle.dump(index_list, f2)\n",
        "f2.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}